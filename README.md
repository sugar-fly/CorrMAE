# CorrMAE
CorrMAE: Pre-training Correspondence Transformers with Masked Autoencoder
